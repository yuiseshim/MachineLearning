{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', \n",
    "    'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', \n",
    "    'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', \n",
    "    'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO\n",
    "http://cocodataset.org/#home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ./COCO/train2014.zip\n",
      "Decompression\n",
      "Save: ./COCO/val2014.zip\n",
      "Decompression\n",
      "Save: ./COCO/test2014.zip\n",
      "Decompression\n",
      "Save: ./COCO/test2015.zip\n",
      "Decompression\n"
     ]
    }
   ],
   "source": [
    "####### Download #######\n",
    "def download(url, dirname='./', filename=None):\n",
    "    import re\n",
    "    import os\n",
    "    import urllib.request as request\n",
    "    from urllib.error import URLError, HTTPError\n",
    "    import zipfile\n",
    "    if filename == None:\n",
    "        pattern = re.compile('[^/]+$')\n",
    "        filename = pattern.findall(url)[0]\n",
    "    filename = os.path.join(dirname, filename)\n",
    "    if not os.path.exists(filename):\n",
    "        try:\n",
    "            request.urlretrieve(url, filename)\n",
    "            print('Save: {}'.format(filename))\n",
    "        except HTTPError as e:\n",
    "            print('The server couldn\\'t fulfill the request.')\n",
    "            print('Error code: ', e.code)\n",
    "        except URLError as e:\n",
    "            print('We failed to reach a server.')\n",
    "            print('Reason: ', e.reason)\n",
    "    else:\n",
    "        print('The file already exists. ')\n",
    "        \n",
    "    with zipfile.ZipFile(filename, 'r') as zf:\n",
    "        zf.extractall(dirname)\n",
    "        print('Decompression')\n",
    "        \n",
    "datasets = [\n",
    "    'http://images.cocodataset.org/annotations/annotations_trainval2014.zip', \n",
    "    'http://images.cocodataset.org/annotations/image_info_test2014.zip', \n",
    "    'http://images.cocodataset.org/annotations/image_info_test2015.zip', \n",
    "    'http://images.cocodataset.org/annotations/annotations_trainval2017.zip', \n",
    "    'http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip', \n",
    "    'http://images.cocodataset.org/annotations/image_info_test2017.zip', \n",
    "    'http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip', \n",
    "    \n",
    "    'http://images.cocodataset.org/zips/train2014.zip', \n",
    "    'http://images.cocodataset.org/zips/val2014.zip', \n",
    "    'http://images.cocodataset.org/zips/test2014.zip', \n",
    "    'http://images.cocodataset.org/zips/test2015.zip', \n",
    "    'http://images.cocodataset.org/zips/train2017.zip', \n",
    "    'http://images.cocodataset.org/zips/val2017.zip', \n",
    "    'http://images.cocodataset.org/zips/test2017.zip', \n",
    "    'http://images.cocodataset.org/zips/unlabeled2017.zip', \n",
    "]\n",
    "for dataset in datasets:\n",
    "    download(url=dataset, dirname='./COCO/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny-ImageNet\n",
    "https://tiny-imagenet.herokuapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'http://cs231n.stanford.edu/tiny-imagenet-200.zip', \n",
    "]\n",
    "for dataset in datasets:\n",
    "    download(url=dataset, dirname='./tinyImageNet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet\n",
    "http://image-net.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashonista\n",
    "http://vision.is.tohoku.ac.jp/~kyamagu/ja/research/clothing_parsing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'http://vision.is.tohoku.ac.jp/~kyamagu/ja/research/paperdoll/fashionista-v0.2.1.tgz', \n",
    "    'http://vision.is.tohoku.ac.jp/~kyamagu/ja/research/clothing_parsing/fashionista_v0.2.tgz', \n",
    "    'http://vision.is.tohoku.ac.jp/~kyamagu/ja/research/clothing_parsing/unannotated_v0.1.tgz', \n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
